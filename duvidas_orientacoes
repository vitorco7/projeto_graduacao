Orientação 20250415

OK -> Com as métricas físicas escolhidas, tentar obter as métricas mais equivalentes dos cgroups.(otimizar os outputs do prometheus)

OK -> Após definidas as métricas virtuais, analisar os dados obtidos no prometheus (otimização)

OK -> Fazer o mesmo para os docker metrics

??? -> Com os dados organizados, montar o dash no grafana.
        OK -> Será ajustado no Grafana (tem suporte nativo pra isso) - Ajustar Timezone das medidas
        OK -> Configurar volume do prometheus para persistencia de dados (importante escrever sobre as questões de permissão de escrita nos volumes)

Com o dash pronto, desenvolver melhor as limitações de hardware

disk

physical_disk_free
physical_disk_total
physical_disk_inodes_free

cpu
physical_cpu_usage_idle
physical_cpu_usage_iowait
physical_cpu_usage_system
physical_cpu_usage_user

disk i/o
physical_diskio_read_bytes
physical_diskio_write_bytes
physical_diskio_io_time
physical_diskio_io_util

memory
physical_mem_free
physical_mem_total
physical_mem_swap_free
physical_mem_swap_total

network
physical_net_bytes_recv
physical_net_bytes_sent
physical_net_drop_out
physical_net_drop_in
physical_net_err_in
physical_net_err_out

process
physical_processes_running
physical_processes_sleeping
physical_processes_total
physical_processes_zombies

Critério geral utilizado para escolher quais métricas usar -> o mais cross-platform possível. Exemplo: se uma métrica é específica para Linux, é descartada.

Physical device - tenho quais inputs vou usar, agora falta definir quais medidas vou usar

Virtual device - posso escolher varias coisas do cgroups, mas preciso escolher as medidas -> a dica é escolher medidas que façam overlap com o physical device

Orientação 20250408

Consegui atualizar o cgroups do note do trabalho para a v2, permitindo assim rodar meu projeto uniformemente em ambas as máquinas (pessoal e trabalho) -->importante ter uma observação sobre isso na escrita

p0 -> preciso analisar com mais calma, mas visto que consegui rodar meu projeto na máquina do trabalho, observei que NÃO tive esse problema de gaps nas medições - minha teoria é que meu desktop possa estar gargalando as medições.  --> investigar com mais profundidade (talvez derrubar alguns serviços para avaliar)

p1 e p2 - Ao invés de continuar lendo sobre quais métricas do cgroups são importantes para escolher quais usar, decidi ver primeiro quais métricas eu consigo a partir de um agente rodando num host real.
Para isso, botei o Telegraf rodando no notebook do trabalho (ubuntu 20). Problema - decidir qual plugin usar (aparentemente posso usar mais de 1 plugin pra coletar as mesmas métricas. Como escolher? Como não perder muito tempo validando melhor/pior escolha? No momento não tenho uma referência pra validação pra comparar quem é melhor ou pior.)
Estou analisando um por um por ver que métricas obtenho para ter uma ideia melhor

Orientação 20250401

1 - Tenho implementado meu projeto em 2 pcs - Note do trabalho (Ubuntu 20 cgroups v1) e Desktop pessoal (Ubuntu 24 cgroups v2). Essas diferenças de versoes nos cgroups acarreta em problemas de compatibilidade, e adaptar o projeto para lidar com ambas as versoes me preocupa por poder estar introduzindo mais distorções. Exemplo: não sei se o cgroups v1 e v2 lêem da mesma forma e obtém os mesmos dados.
--> isso é uma observaão importante de se ter quando explicicatar o processo de mediãção

2 - Estou lendo sobre o QEMU para simular o Raspberry. Dicas?
-> se ficar muito difícil, não fazer


-> a escolha atende à uma expectativa - Qual é a expectativa? Entao escolho para atender esta expectativa

Orientação 20250325

1 - perguntar dos agentes (telegraf, cAdvisor, node exporter) - quais situações usar -> usar telegraf pela isonomia (para evitar distorções)
2 - Quais stress tests são interessantes?
Performar todos (CPU, memória, disco, network) ao mesmo tempo ou separadamente? Qual a carga dos testes? -> primeiramente fazer testes individuais, e depois testes agregados com todos.
3 - terei de falar do zabbix na escrita, mas não tenho tanto embasamento pra justificar a troca. Só não estava confortável/gostando de usar. Não tenho algo muito técnico, não foi feito um estudo comparativo profundo.
->a usabilidade também é um fator. Se eu estava utilizando e não estava gostando da interface e ou usabilidade, isso é um custo a ser levado em conta