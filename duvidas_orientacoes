Orientação 20250527

Fiz mais uma tentativa de adicionar um dispositivo Android no monitoramento. No caso, o meu celular. No entanto, tive muitos problemas de permissionamento do sistema. Se eu obtivesse um android rooteado, conseguiria facilmente realizar a aquisição de dados. No entanto, como não tenho acesso a um dispositivo rooteado, não consegui avançar nesse ponto. Aí entramos novamente na tentativa de simular um dispositivo Android rooteado na minha máquina, o que optamos por não fazer.



Orientação 20250506

Consegui adicionar métricas de rede  e processos aos containers!!!

{1 - Atualizei a estratégia de coleta de métricas do Docker: agora estou utilizando o plugin inputs.docker diretamente no telegraf.conf do host. Dessa forma, o Telegraf coleta métricas diretamente do socket do Docker daemon (/var/run/docker.sock), garantindo maior precisão, já que os dados vêm da mesma fonte usada pelo próprio Docker para monitoramento. Com isso, obtenho métricas essenciais como uso de CPU, memória, disco (I/O) e rede. Esses dados podem ser usados para comparações qualitativas com as métricas coletadas por Telegrafs rodando dentro dos containers.

Mas fica a reflexão: faz sentido comparar métricas entre dispositivos virtuais? Quando o objetivo era comparar máquinas físicas versus containers, essa comparação qualitativa era justificável. Porém, ao comparar container versus container, será que essa análise ainda se sustenta? Há valor prático em comparar dispositivos virtuais entre si nesses termos?

--> Realmente não faz sentido, logo não é necessário fazer esse levantamento.
}
2 - Avaliar gráficos apresentados
  #2.1 - O quão "feio" é o fato de haver gráficos "Physical Hosts Only"? - NAO É FEIO, ESTÁ TUDO BEM
  #2.2 - Seria interessante calcular medias nos gráficos Time Series? Nao tem necessidade, pois ja temos muitos dados, poderia gerar poluição visual
  #2.3 - Gauge normal ou Bar Gauge? Gauge Normal
  #2.4 - No CPU Time Series - Normal ou Stacked? Normal
  #2.5 - Definir intervalos padrão de pontos nos gŕaficos (cpu e mem a cada 5s?) - Taxa de amostragem padrao do disco pode ser mais longa = 1m. Deixar a opção do usuario de escolher qual a taxa de amostragem (deixar opçoes como 5s, 15s ou 1m, 2m(disk), 5m(disk))
  #2.6 - Validações/Observações:
      ->CPU
        #-Virtual Hosts não tem Total Load ou Other Load (pois preciso da metrica "free" e containers nao tem. Eu ate poderia calcular mas aí teria de coletar varias outras metricas pra fazer um somatorio) - tá OK
        #- Bar Gauge ou Gauge normal? - Normal
      ->Mem
        #-Usar apenas o Bar Gauge pra diferenciar visualmente dos Gauges do CPU? - Normal
      ->Disk
        #-Time to Full Disk está meio errático - avaliar posteriormente no texto
        #-Disk usage de pizza é uma visualização muito ruim. Trocar por outra? Qual? Nao precisa trocar
      ->Disk I/O
        #-Ter um disclaimer que os Alpine devices não tem I/O metrics - Adicionado um comentário no row
        #-Gráficos de throughput continuam mostrando dados mesmo depois do disco ter sido unmount.-> Eles somem depois que passa a janela de tempo (ele mantém o last value quando para de vir dados mas ainda está dentro do timespan)
      ->Network
        -Dropped & Error Packets - qual a unidade deles?
        -Dropped & Error Packets sempre zerado... validar se está correto...
        -Responsividade para timespans não está muito boa?
        #-Bar Gauges Bugados - barras sempre preenchidas
        -Responsividade aos timespans?
        #-Virtual Hosts Network Inbound Traffic - dados pobres. Investir em outro simulador de carga?  - nao precisa, estao ok - validado com o físico
      ->Processes
      ->Trends Over Time
        #-CPU normal ou stacked? (mesmo problema da falta da métrica "free") - Normal
        -Network - Mesmos problemas da seção Network citados acima
  #2.7 - Validar $__intervals e $__ranges nas queries
  #2.8 - Permitir a seleção de múltiplas labels -> Usar CTRL+CLICK

#ok - p0 - montar o dash do grafana{
  if (comparações qualitativas container x container) != true{
    estrutura dashboard pronta?
    }
  else
    faltam as comparaçoes
}

#ok - 3 - Estou com dificuldadas para entender o sincronismo entre as marcações de tempo obtidas nos testes (docker logs) e os pontos nos gráficos. --> essa reflexao vale a pena acontecer no texto posteriormente


  #p2 - Configurar os stress tests de acordo com as diretrizes definidas (testes individuais e depois simultaneos) - estao funcionando perfeitamente na visao MACRO

----TO DO----
{
ok - Configurar smtp server para envio dos alertas por email
Configurar Alertas
--> fazer o log do banco do prometheus 1x por dia - quebrar em varios arquivos menores (diarios)
}

Orientação 20250429

  p0 - montar o dash do grafana - praticamente fechado, so fechar os ajustes finos

  p1 - Alarmes e Alertas

  p2 - Configurar os stress tests de acordo com as diretrizes definidas (testes individuais e depois simultaneos)

  p3(opcional) - estudo dos virtualizadores e tentar implementar o Raspberry + Telegraf (se der certo, segue para Android)


dashboard cockpit - deixar os gauges à mostra sempre, e os temporais minimzados

fazer o log do banco do prometheus 1x por dia - quebrar em varios arquivos menores (diarios)


Estou tentando evitar ao máximo configurações via interface, tentando fazer tudo "as code", por questões de aprendizagem, versionamento e robustez.
Por conta disso, estou tentando usar o Grafana VSCode extension para editar dashboards pelo proprio VSCode. Mas bati num erro:
Failed to save dashboard
<!DOCTYPE html> <html lang="en"> <head> <meta charset="utf-8"> <title>Error</title> </head> <body> <pre>Payload Too Large</pre> </body> </html>


O payload de dashboards muito grandes ultrapassa o limite de tamanho de payload da api do grafana ou extensao do vscode.

Toda e qualquer alteração feita via UI do Grafana é salva no grafana/config/grafana.db, uma base SQLite interna do grafana. Como isso fica num volume, há persistencia nos dados. Mas como são dados de runtime, não consigo versionar no git.

Orientação 20250415

OK -> Com as métricas físicas escolhidas, tentar obter as métricas mais equivalentes dos cgroups.(otimizar os outputs do prometheus)

OK -> Após definidas as métricas virtuais, analisar os dados obtidos no prometheus (otimização)

OK -> Fazer o mesmo para os docker metrics

??? -> Com os dados organizados, montar o dash no grafana.
        OK -> Será ajustado no Grafana (tem suporte nativo pra isso) - Ajustar Timezone das medidas
        OK -> Configurar volume do prometheus para persistencia de dados (importante escrever sobre as questões de permissão de escrita nos volumes)

Com o dash pronto, desenvolver melhor as limitações de hardware

disk

physical_disk_free
physical_disk_total
physical_disk_inodes_free

cpu
physical_cpu_usage_idle
physical_cpu_usage_iowait
physical_cpu_usage_system
physical_cpu_usage_user

disk i/o
physical_diskio_read_bytes
physical_diskio_write_bytes
physical_diskio_io_time
physical_diskio_io_util

memory
physical_mem_free
physical_mem_total
physical_mem_swap_free
physical_mem_swap_total

network
physical_net_bytes_recv
physical_net_bytes_sent
physical_net_drop_out
physical_net_drop_in
physical_net_err_in
physical_net_err_out

process
physical_processes_running
physical_processes_sleeping
physical_processes_total
physical_processes_zombies

Critério geral utilizado para escolher quais métricas usar -> o mais cross-platform possível. Exemplo: se uma métrica é específica para Linux, é descartada.

Physical device - tenho quais inputs vou usar, agora falta definir quais medidas vou usar

Virtual device - posso escolher varias coisas do cgroups, mas preciso escolher as medidas -> a dica é escolher medidas que façam overlap com o physical device

Orientação 20250408

Consegui atualizar o cgroups do note do trabalho para a v2, permitindo assim rodar meu projeto uniformemente em ambas as máquinas (pessoal e trabalho) -->importante ter uma observação sobre isso na escrita

p0 -> preciso analisar com mais calma, mas visto que consegui rodar meu projeto na máquina do trabalho, observei que NÃO tive esse problema de gaps nas medições - minha teoria é que meu desktop possa estar gargalando as medições.  --> investigar com mais profundidade (talvez derrubar alguns serviços para avaliar)

p1 e p2 - Ao invés de continuar lendo sobre quais métricas do cgroups são importantes para escolher quais usar, decidi ver primeiro quais métricas eu consigo a partir de um agente rodando num host real.
Para isso, botei o Telegraf rodando no notebook do trabalho (ubuntu 20). Problema - decidir qual plugin usar (aparentemente posso usar mais de 1 plugin pra coletar as mesmas métricas. Como escolher? Como não perder muito tempo validando melhor/pior escolha? No momento não tenho uma referência pra validação pra comparar quem é melhor ou pior.)
Estou analisando um por um por ver que métricas obtenho para ter uma ideia melhor

Orientação 20250401

1 - Tenho implementado meu projeto em 2 pcs - Note do trabalho (Ubuntu 20 cgroups v1) e Desktop pessoal (Ubuntu 24 cgroups v2). Essas diferenças de versoes nos cgroups acarreta em problemas de compatibilidade, e adaptar o projeto para lidar com ambas as versoes me preocupa por poder estar introduzindo mais distorções. Exemplo: não sei se o cgroups v1 e v2 lêem da mesma forma e obtém os mesmos dados.
--> isso é uma observaão importante de se ter quando explicicatar o processo de mediãção

2 - Estou lendo sobre o QEMU para simular o Raspberry. Dicas?
-> se ficar muito difícil, não fazer


-> a escolha atende à uma expectativa - Qual é a expectativa? Entao escolho para atender esta expectativa

Orientação 20250325

1 - perguntar dos agentes (telegraf, cAdvisor, node exporter) - quais situações usar -> usar telegraf pela isonomia (para evitar distorções)
2 - Quais stress tests são interessantes?
Performar todos (CPU, memória, disco, network) ao mesmo tempo ou separadamente? Qual a carga dos testes? -> primeiramente fazer testes individuais, e depois testes agregados com todos.
3 - terei de falar do zabbix na escrita, mas não tenho tanto embasamento pra justificar a troca. Só não estava confortável/gostando de usar. Não tenho algo muito técnico, não foi feito um estudo comparativo profundo.
->a usabilidade também é um fator. Se eu estava utilizando e não estava gostando da interface e ou usabilidade, isso é um custo a ser levado em conta